{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "import numpy as np, seaborn as sns, pandas as pd\n",
    "import nltk, nltk.sentiment, sklearn\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert list to pd.series\n",
    "#doc1_str = pd.Series([''.join(doc1)])\n",
    "\n",
    "#Preprocessing - tokenize and lower case pdf-strings\n",
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "def preprocessing(string):\n",
    "    string = string.lower()\n",
    "    string = tokenizer.tokenize(string)\n",
    "    return string\n",
    "\n",
    "#Apply positive/negative sets on pdf-string\n",
    "#tok_doc1 = doc1_str.apply(preprocessing)\n",
    "\n",
    "def count_dictionary(document_elem, dictionary):\n",
    "    lst = []\n",
    "    for word in document_elem:\n",
    "        if (word in dictionary):\n",
    "            lst.append(word)\n",
    "    return len(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDF extractor script. Creates a list separated per page.\n",
    "def pdf_extractor(path):\n",
    "    pdf_file = open(path, 'rb')\n",
    "    read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
    "    number_of_pages = read_pdf.getNumPages()\n",
    "    c = collections.Counter(range(number_of_pages))\n",
    "    res1 = []\n",
    "    for i in range(len(c)):\n",
    "        page = read_pdf.getPage(i)\n",
    "        page_content = page.extractText()\n",
    "        res1.append(page_content)\n",
    "    return res1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#Create set for negative and positive lexicon\n",
    "negative = set(requests.get('http://ptrckprry.com/course/ssd/data/negative-words.txt').text.split(';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;')[2].split('\\n')[2:])\n",
    "positive = set(requests.get('http://ptrckprry.com/course/ssd/data/positive-words.txt').text.split(';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;')[2].split('\\n')[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now treating file: ppp000001e.pdf\n",
      "Iterate: 0\n",
      "Now treating file: ppp000002e.pdf\n",
      "Iterate: 1\n",
      "Now treating file: ppp000003e.pdf\n",
      "Iterate: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>85</td>\n",
       "      <td>0.006086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>41</td>\n",
       "      <td>0.006694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>0.004838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1         2\n",
       "0  122  85  0.006086\n",
       "1   70  41  0.006694\n",
       "2   70  48  0.004838"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Sebastian file path\n",
    "basedir = r'C:\\Users\\sebag\\Documents\\GitHub\\SDS Group 35\\Exam_Project\\Minutes_PDF'\n",
    "\n",
    "def sentiment_analysis(pos, neg, file_path):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    average_tone = []\n",
    "    i = 0\n",
    "    for fn in os.listdir(file_path):\n",
    "        print('Now treating file: ' + fn + '\\nIterate: ' + str(i))\n",
    "        doc = pdf_extractor(file_path + '\\\\' + fn)\n",
    "        doc = pd.Series([''.join(doc)])\n",
    "        doc = doc.apply(preprocessing)\n",
    "        \n",
    "        pos_words.append(count_dictionary(doc[0], pos))\n",
    "        neg_words.append(count_dictionary(doc[0], neg))\n",
    "        average_tone.append((pos_words[i]-neg_words[i])/len(doc[0]))\n",
    "        \n",
    "        i += 1\n",
    "        #date = re.findall(r'\\d+', fn)\n",
    "    df = pd.DataFrame(zip(pos_words, neg_words, average_tone))\n",
    "    return df\n",
    "\n",
    "sent_df = sentiment_analysis(positive, negative, testdir)\n",
    "sent_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now treating file: ppp000203e.pdf\n",
      "Iterate: 0\n",
      "Now treating file: ppp000322e.pdf\n",
      "Iterate: 1\n",
      "Now treating file: ppp000504e.pdf\n",
      "Iterate: 2\n",
      "Now treating file: ppp000607e.pdf\n",
      "Iterate: 3\n",
      "Now treating file: ppp000706e.pdf\n",
      "Iterate: 4\n",
      "Now treating file: ppp000816e.pdf\n",
      "Iterate: 5\n",
      "Now treating file: ppp001024e.pdf\n",
      "Iterate: 6\n",
      "Now treating file: ppp001220e.pdf\n",
      "Iterate: 7\n",
      "Now treating file: ppp010201e.pdf\n",
      "Iterate: 8\n",
      "Now treating file: ppp010326e.pdf\n",
      "Iterate: 9\n",
      "Now treating file: ppp010426e.pdf\n",
      "Iterate: 10\n",
      "Now treating file: ppp010530e.pdf\n",
      "Iterate: 11\n",
      "Now treating file: ppp010614e.pdf\n",
      "Iterate: 12\n",
      "Now treating file: ppp010705e.pdf\n",
      "Iterate: 13\n",
      "Now treating file: ppp010823e.pdf\n",
      "Iterate: 14\n",
      "Now treating file: ppp010917e.pdf\n",
      "Iterate: 15\n",
      "Now treating file: ppp011015e.pdf\n",
      "Iterate: 16\n",
      "Now treating file: ppp011108e.pdf\n",
      "Iterate: 17\n",
      "Now treating file: ppp011204e.pdf\n",
      "Iterate: 18\n",
      "Now treating file: ppp020207e.pdf\n",
      "Iterate: 19\n",
      "Now treating file: ppp020318e.pdf\n",
      "Iterate: 20\n",
      "Now treating file: ppp020425e.pdf\n",
      "Iterate: 21\n",
      "Now treating file: ppp020605e.pdf\n",
      "Iterate: 22\n",
      "Now treating file: ppp020704e.pdf\n",
      "Iterate: 23\n",
      "Now treating file: ppp020815e.pdf\n",
      "Iterate: 24\n",
      "Now treating file: ppp021016e.pdf\n",
      "Iterate: 25\n",
      "Now treating file: ppp021114e.pdf\n",
      "Iterate: 26\n",
      "Now treating file: ppp021204e.pdf\n",
      "Iterate: 27\n",
      "Now treating file: ppp030206e.pdf\n",
      "Iterate: 28\n",
      "Now treating file: ppp030317e.pdf\n",
      "Iterate: 29\n",
      "Now treating file: ppp030424e.pdf\n",
      "Iterate: 30\n",
      "Now treating file: ppp030604e.pdf\n",
      "Iterate: 31\n",
      "Now treating file: ppp030703e.pdf\n",
      "Iterate: 32\n",
      "Now treating file: ppp030814e.pdf\n",
      "Iterate: 33\n",
      "Now treating file: ppp031015e.pdf\n",
      "Iterate: 34\n",
      "Now treating file: ppp031204e.pdf\n",
      "Iterate: 35\n",
      "Now treating file: ppp040205e.pdf\n",
      "Iterate: 36\n",
      "Now treating file: ppp040331e.pdf\n",
      "Iterate: 37\n",
      "Now treating file: ppp040428e.pdf\n",
      "Iterate: 38\n",
      "Now treating file: ppp040527e.pdf\n",
      "Iterate: 39\n",
      "Now treating file: ppp040623e.pdf\n",
      "Iterate: 40\n",
      "Now treating file: ppp040819e.pdf\n",
      "Iterate: 41\n",
      "Now treating file: ppp041013e.pdf\n",
      "Iterate: 42\n",
      "Now treating file: ppp041208e.pdf\n",
      "Iterate: 43\n",
      "Now treating file: ppp050127e.pdf\n",
      "Iterate: 44\n",
      "Now treating file: ppp050314e.pdf\n",
      "Iterate: 45\n",
      "Now treating file: ppp050428e.pdf\n",
      "Iterate: 46\n",
      "Now treating file: ppp050620e.pdf\n",
      "Iterate: 47\n",
      "Now treating file: ppp050823e.pdf\n",
      "Iterate: 48\n",
      "Now treating file: ppp051019e.pdf\n",
      "Iterate: 49\n",
      "Now treating file: ppp051201e.pdf\n",
      "Iterate: 50\n",
      "Now treating file: ppp060119e.pdf\n",
      "Iterate: 51\n",
      "Now treating file: ppp060308e.pdf\n",
      "Iterate: 52\n",
      "Now treating file: ppp060427e.pdf\n",
      "Iterate: 53\n",
      "Now treating file: ppp060619e.pdf\n",
      "Iterate: 54\n",
      "Now treating file: ppp060829e.pdf\n",
      "Iterate: 55\n",
      "Now treating file: ppp061025e.pdf\n",
      "Iterate: 56\n",
      "Now treating file: ppp061214e.pdf\n",
      "Iterate: 57\n",
      "Now treating file: ppp070214e.pdf\n",
      "Iterate: 58\n",
      "Now treating file: ppp070329e.pdf\n",
      "Iterate: 59\n",
      "Now treating file: ppp070503e.pdf\n",
      "Iterate: 60\n",
      "Now treating file: ppp070619e.pdf\n",
      "Iterate: 61\n",
      "Now treating file: ppp070906e.pdf\n",
      "Iterate: 62\n",
      "Now treating file: ppp071029e.pdf\n",
      "Iterate: 63\n",
      "Now treating file: ppp071218e.pdf\n",
      "Iterate: 64\n",
      "Now treating file: ppp080212e.pdf\n",
      "Iterate: 65\n",
      "Now treating file: ppp080422e.pdf\n",
      "Iterate: 66\n",
      "Now treating file: ppp080702e.pdf\n",
      "Iterate: 67\n",
      "Now treating file: ppp080903e.pdf\n",
      "Iterate: 68\n",
      "Now treating file: ppp081008e.pdf\n",
      "Iterate: 69\n",
      "Now treating file: ppp081022e.pdf\n",
      "Iterate: 70\n",
      "Now treating file: ppp081203e.pdf\n",
      "Iterate: 71\n",
      "Now treating file: ppp090210e.pdf\n",
      "Iterate: 72\n",
      "Now treating file: ppp090420e.pdf\n",
      "Iterate: 73\n",
      "Now treating file: ppp090701e.pdf\n",
      "Iterate: 74\n",
      "Now treating file: ppp090916e.pdf\n",
      "Iterate: 75\n",
      "Now treating file: ppp091021e.pdf\n",
      "Iterate: 76\n",
      "Now treating file: ppp091215e.pdf\n",
      "Iterate: 77\n",
      "Now treating file: ppp100224e.pdf\n",
      "Iterate: 78\n",
      "Now treating file: ppp100503e.pdf\n",
      "Iterate: 79\n",
      "Now treating file: ppp100630e.pdf\n",
      "Iterate: 80\n",
      "Now treating file: ppp100901e.pdf\n",
      "Iterate: 81\n",
      "Now treating file: ppp101025e.pdf\n",
      "Iterate: 82\n",
      "Now treating file: ppp101214e.pdf\n",
      "Iterate: 83\n",
      "Now treating file: ppp110214e.pdf\n",
      "Iterate: 84\n",
      "Now treating file: ppp110419e.pdf\n",
      "Iterate: 85\n",
      "Now treating file: ppp110704e.pdf\n",
      "Iterate: 86\n",
      "Now treating file: ppp110920e.pdf\n",
      "Iterate: 87\n",
      "Now treating file: ppp111026e.pdf\n",
      "Iterate: 88\n",
      "Now treating file: ppp111219e.pdf\n",
      "Iterate: 89\n",
      "Now treating file: ppp120215e.pdf\n",
      "Iterate: 90\n",
      "Now treating file: ppp120417e.pdf\n",
      "Iterate: 91\n",
      "Now treating file: ppp120703e.pdf\n",
      "Iterate: 92\n",
      "Now treating file: ppp120905e.pdf\n",
      "Iterate: 93\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'/Contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-bbbd4aa2afa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment_analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasedir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-d96e97b73176>\u001b[0m in \u001b[0;36msentiment_analysis\u001b[1;34m(pos, neg, file_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Now treating file: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\nIterate: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-0d2088c5cad4>\u001b[0m in \u001b[0;36mpdf_extractor\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_pdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpage_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mres1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PyPDF2\\pdf.py\u001b[0m in \u001b[0;36mextractText\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2591\u001b[0m         \"\"\"\n\u001b[0;32m   2592\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"/Contents\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mContentStream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContentStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PyPDF2\\generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '/Contents'"
     ]
    }
   ],
   "source": [
    "sent_df = sentiment_analysis(positive, negative, basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122]\n",
      "6080\n"
     ]
    }
   ],
   "source": [
    "pos_words = []\n",
    "doc = pdf_extractor(r'C:\\Users\\sebag\\Documents\\GitHub\\SDS Group 35\\Exam_Project\\Minutes_PDF\\ppp000203e.pdf')\n",
    "doc = pd.Series([''.join(doc)])\n",
    "doc = doc.apply(preprocessing)\n",
    "count_dictionary(doc[0], negative)\n",
    "pos_words.append(count_dictionary(doc[0], positive))\n",
    "print(pos_words)\n",
    "print(len(doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #3 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-09c714f1a030>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#date = re.findall(r'\\d+', fn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_tone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #3 must support iteration"
     ]
    }
   ],
   "source": [
    "testdir = r'C:\\Users\\sebag\\Documents\\GitHub\\Exam\\Test folder'\n",
    "pos_words = []\n",
    "neg_words = []\n",
    "average_tone = []\n",
    "i = 0\n",
    "\n",
    "for fn in os.listdir(testdir):\n",
    "    doc = pdf_extractor(testdir + '\\\\' + fn)\n",
    "    doc = pd.Series([''.join(doc)])\n",
    "    doc = doc.apply(preprocessing)\n",
    "    pos_words.append(count_dictionary(doc[0], positive))\n",
    "    neg_words.append(count_dictionary(doc[0], negative))\n",
    "    average_tone = (pos_words[i]-neg_words[i])/len(doc[0])\n",
    "        \n",
    "    i += 1\n",
    "    #date = re.findall(r'\\d+', fn)\n",
    "df = pd.DataFrame(zip(pos_words, neg_words, average_tone))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
